---
title: "TMA4250-Project-2"
author: "Ole Riddervold, Ole Kristian Skogly"
date: "2023-03-06"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# install.packages("ggnewscale")
# install.packages("scales")

library(spatial)
library(MASS)
library(ggplot2)
library(patchwork)
library(glue)
library(tidyverse)
library(reshape2)
library(ggnewscale)
library(scales)
library(latex2exp)
library(Orcs)
```


## Loading data
```{r}
cells   <- read.table("data/cells.dat", skip=3, col.names=c('x', 'y'))
redwood <- read.table("data/redwood.dat", skip=3, col.names=c('x', 'y'))
pines   <- read.table("data/pines.dat", skip=3, col.names=c('x', 'y'))
```

## Exploring data
```{r}
head(cells)
head(redwood)
head(pines)
```


# Problem 1
## a)
```{r}
display_point_patterns <- function(dataframes, titles, pts=1, txs=11) {
  # Plots point patterns for dataframes with point data
  # Args: Dataframes and titles as lists of the same lengths
  # Returns: None
  n <- length(dataframes)
  do.call(
    wrap_plots,
    lapply(1:n, function(i) {
      ggplot(dataframes[[i]]) + geom_point(aes(x, y), size=pts) +
        xlab('x [m]') + ylab('y [m]') + labs(title=titles[i]) +
        coord_fixed() + theme(text=element_text(size=txs))
    })
  )
}
```

```{r}
plot_titles = c(
  "Cells",
  "Redwood",
  "Pines"
)

# png("figures/1_a.# png", width=3600, height=1200, units="px", res=300) # Saving

display_point_patterns(list(
  cells,
  redwood,
  pines
), plot_titles)
```

## b)
The L-function is defined by
\begin{equation}
  L(r) = \sqrt[d]{\frac{K(r)}{b_d}}
\end{equation}

where
\begin{align}
  K(r) &= \frac{1}{\lambda}\mathbb{E}_\mathbf{0}\left[N\left(B_r(\mathbf{0}\backslash\{\mathbf{0}\})\right)\right] \\
  b_d = \nu(B_1(\mathbf{0}))
\end{align},
$B_r(\mathbf{x})$ denotes a ball of radius $r$ centered in $\mathbf{x}$ in the relevant space (here $\mathbb{R}^2$), and $\nu$ denotes the volume-function. The K-function $K(r)$ can be interpreted as the ratio between the expected number of points in a ball centered at $\mathbf{0}$ excluding the origin itself, *given* that there is a point at the origin, and the rate of the point process itself. Therefore one can say that the L-function is a variant of the K-function that takes the curse of dimensionality, i.e. the fact that points get further apart the larger the dimension, into account. In $\mathbb{R}^2$, we have
\begin{equation}
  L(r) = \sqrt(\frac{K(r)}{\pi})
\end{equation}

Estimation of the L-function:
```{r}
pp.cells   <- ppinit("data/cells.dat")
pp.redwood <- ppinit("data/redwood.dat")
pp.pines   <- ppinit("data/pines.dat")

L.cells   <- data.frame(Kfn(pp.cells, fs=1.0)[1:2])
L.redwood <- data.frame(Kfn(pp.redwood, fs=1.0)[1:2])
L.pines   <- data.frame(Kfn(pp.pines, fs=1.0)[1:2])
```

L-function plotting:
```{r}
display_L_functions <- function(dataframes, titles) {
  # Plots K-functions and affine lines with growth 1 for comparison
  # Args: Dataframes and titles as same length lists
  # Returns: None
  n <- length(dataframes)
  do.call(
    wrap_plots,
    lapply(1:n, function(i) {
      ni <- nrow(dataframes[[i]])
      df <- dataframes[[i]] %>% mutate(xline=1:ni/100, yline=1:ni/100)
      ggplot(df) + geom_point(aes(x, y), size=1, col="red") +
        xlab('r') + ylab('L(r)') + labs(title=titles[i]) +
        geom_line(aes(xline, yline)) +
        coord_fixed()
    })
  )
}
```


```{r}
# png("figures/1_b.# png", width=3600, height=1200, units="px", res=300) # Saving

display_L_functions(list(
  L.cells,
  L.redwood,
  L.pines
), titles=plot_titles)
```


## c)
```{r}
simulate_R2_unif <- function(n, m) {
  # Simulates a homogeneous Poisson point process on R^2 in m realizations on [0, 1]x[0, 1].
  # Args: n (amount of points to simulate in each realization) and m (amount of realizations)
  # Returns: mxnx2 array.
  dims <- c(m, n, 2)
  realizations <- array(runif(m*n*2), dims)
  return(realizations)
}
```

```{r}
calculate_R2_L_functions <- function(realizations) {
  # Given realizations of some point process in the form of an array, calculates
  # the L-function for each realiztion and returns as an array.
  # Args: realizations (mxnx2 array)
  #         - m: Amount of realzations
  #         - n: Amount of points per realization
  # Returns: mxn-array
  d <- dim(realizations)
  L <- array(rep(0, prod(d[1:2])), d[1:2])
  for (i in 1:d[1]) {
    df <- data.frame(realizations[i, , ])
    colnames(df) <- c('x', 'y')
    L[i, ] <- Kfn(df, fs=1.0)$y
  }
  return(L)
}
```

```{r}
R2_L_function_stats <- function(L_functions) {
  # Given an array of m L-functions at n points, calculates mean and 90%
  # confidence intervals.
  # Args: L_functions (mxn)
  # Returns: Dataframe of L-functions
  stats <- L_functions %>% melt() %>%
    group_by(Var2) %>%
    summarize(
      mean=mean(value),
      CI90=qt(0.05, length(value))*sd(value)*sqrt(1 + 1/length(value))
    )
  return(stats)
}
```

```{r}
simulate_R2_ppp_Lfn <- function(n, m) {
  # Simulates a Poisson point process conditional on N = n, and returning
  # a dataframe containing empirically estimated L-function and 90% CI.
  return(
    simulate_R2_unif(n, m) %>%
      calculate_R2_L_functions() %>%
      R2_L_function_stats()
  )
}
```

```{r}
display_L_functions_with_ppp_sim <- function(dataframes, titles, m=100) {
  # Plots K-functions and affine lines with growth 1 for comparison
  # Args: Dataframes and titles as same length lists
  # Returns: None
  n <- length(dataframes)
  do.call(
    wrap_plots,
    lapply(1:n, function(i) {
      ni <- nrow(dataframes[[i]])
      simi <- simulate_R2_ppp_Lfn(n=ni, m=m)
      df <- dataframes[[i]] %>% mutate(Lmean=simi$mean, LCI=simi$CI90)
      ggplot(df) + geom_point(aes(x, y), size=1, col="red") +
        geom_line(aes(x, Lmean)) +
        geom_ribbon(aes(x, ymin=Lmean-LCI, ymax=Lmean+LCI), alpha=0.25) +
        xlab('r') + ylab('L(r)') + labs(title=titles[i]) +
        coord_fixed() + theme(text=element_text(size=11))
    })
  )
}
```

```{r}
# png("figures/1_c.# png", width=3600, height=1200, units="px", res=300) # Saving

display_L_functions_with_ppp_sim(list(
  L.cells,
  L.redwood,
  L.pines
), titles=plot_titles)
```


# Problem 2
## a)
```{r}
obspines <- read.table("data/obspines.txt", skip=1, col.names=c('x', 'y', 'obs'))
obsprob <- read.table("data/obsprob.txt", skip=1, col.names=c('x', 'y', 'prob'))
```


```{r}
# png("figures/2_a1.# png", width=2400, height=1900, units="px", res=300) # Saving
ggplot(obspines) +
  geom_tile(aes(x, y, fill=obs)) + scale_fill_gradient(low="white", high="purple") +
  xlab('x [m]') + ylab('y [m]') + 
  coord_fixed() + theme(text=element_text(size=10))

# png("figures/2_a2.# png", width=2400, height=1900, units="px", res=300) # Saving
ggplot(obsprob) + 
  geom_tile(aes(x, y, fill=prob)) + scale_fill_gradient(low='white', high='darkgreen') + 
  xlab('x [m]') + ylab('y [m]') +
  coord_fixed() + theme(text=element_text(size=10))
```


## b)

Estimate from data:
```{r}
remote_estimate_lambda <- function(obs, prob, grid_size) {
  # Estimates lambda based on observed points and detection probabilities
  # Args: obs (Amount of observations in a gridpoint), alpha (detection probabilities)
  # Returns: (float) Estimate of lambda
  C <- grid_size*sum(prob) # Normalizing constant
  lambda_hat <- sum(obs)/C
  return(lambda_hat)
}
```

```{r}
grid_size <- 10^2 # For this particular problem
lambda_hat <- remote_estimate_lambda(obspines$obs, obsprob$prob, grid_size)
lambda_hat
```


```{r}
simulate_pois_dyn_rate <- function(lambda, displacement = 0) {
  # Given some changing rate lambda, draws corresponding amount of samples
  # for each rate.
  # Args:
  #   lambda (array-like): Varying rate of size m
  # Returns:
  #   Poisson samples of size m
  k <- length(lambda)
  return(
    lapply(
      1:k,
      function(i) rpois(1, lambda[i])
    ) %>% unlist() + displacement
  )
}

simulate_ppp_on_grid <- function(grid, poisson_displacement=0) {
  # Simulates a inhomogeneous Poisson point process on a square grid.
  # Args:
  #   grid  (Dataframe): Coordinates and rate (columns x, y, lambda)
  #   cell_size (float): Length of the given cell
  # Returns:
  #   Matrix of points
  k <- nrow(grid)
  n <-  simulate_pois_dyn_rate(grid$lambda, poisson_displacement) # BETTER WAY OF DOING THIS?
  points <- array(
    runif(2*sum(n), min=0, max=cell_size),
    c(sum(n), 2)
  ) %>% data.frame()
  colnames(points) <- c('x', 'y')

  # Adding x- and y-values to each point:
  ind <- 0
  for (i in 1:k) {
    if (n[i] > 0) {
      for (j in 1:n[i]) {
        points$x[ind+j] <- points$x[ind+j] + grid$x[i]
        points$y[ind+j] <- points$y[ind+j] + grid$y[i]
      }
      ind <- ind + n[i]
    }
  }
  return(points)
}
```

```{r}
cell_size <- 10
prior.grid <- obsprob %>% select(c('x', 'y')) %>% mutate(lambda=cell_size^2*lambda_hat)
prior.points_homogeneous_ppp <- replicate(3, simulate_ppp_on_grid(prior.grid), simplify=FALSE)
```

```{r}
# # png("figures/2_c.# png", width=3600, height=1200, units="px", res=300) # Saving

display_point_patterns(
  prior.points_homogeneous_ppp,
  titles=c("", "", ""),
  txs=11
)
```

## d)
```{r}
posterior.grid <- obsprob %>% mutate(lambda=cell_size^2*lambda_hat*(1-prob)) %>% select(-prob)
posterior.points_inhomogeneous_ppp <- replicate(3, simulate_ppp_on_grid(
  posterior.grid, 
  poisson_displacement=obspines$obs
), simplify=FALSE)
```

```{r}
# png("figures/2_d.# png", width=3600, height=1200, units="px", res=300) # Saving

display_point_patterns(
  posterior.points_inhomogeneous_ppp,
  titles=c("", "", ""),
  txs=11
)
```


## e)
```{r}
n <- 500

# Prior:
prior.sim <- replicate(n, simulate_pois_dyn_rate(prior.grid$lambda)) %>% melt() %>% # Simulating and creating a dataframe
  group_by(Var1) %>% summarize(mean=mean(value), std=sd(value)) %>%                 # Grouping and getting mean and std
  bind_cols(obsprob %>% select(c('x', 'y'))) %>% select(-Var1)                      # Concatenating grid coordinates and removing index
prior.sim

# Posterior:
posterior.sim <- replicate(n, simulate_pois_dyn_rate(posterior.grid$lambda, displacement=obspines$obs)) %>% melt() %>%
  group_by(Var1) %>% summarize(mean=mean(value), std=sd(value)) %>%
  bind_cols(obsprob %>% select(c('x', 'y'))) %>% select(-Var1)
posterior.sim
```

```{r}
df_merged <- merge(prior.sim, posterior.sim, by=c('x', 'y'))
colnames(df_merged)[3:length(df_merged)] <- c("prior_mean", "prior_std", "posterior_mean", "posterior_std")
# df_merged

generate_boundary_indices <- function(fnc) {
  # Generates either min or max for mean and std respectively to fit the
  # plotting scheme below of df_merged.
  val <- rep(0, 4)
  val[c(1, 3)] <- df_merged %>% select(c('prior_mean', 'posterior_mean')) %>% fnc()
  val[c(2, 4)] <- df_merged %>% select(c('prior_std', 'posterior_std')) %>% fnc()
  return(val)
}

# Mins and maxes for each of the four plots:
mins <- generate_boundary_indices(min)
maxs <- generate_boundary_indices(max)
col.lwr <- c("white", "green", "white", "green") # Thoughts: Low std: Good (green)
col.upr <- c("purple", "red", "purple", "red")   # Thoughts: High std: Bad (red)

# png("figures/2_e.# png", width=2400, height=1800, units="px", res=300) # Saving

do.call(
  wrap_plots,
  lapply(1:4, function(i) {
    df_merged %>% {
      ggplot(.) +
        geom_tile(aes_string(x='x', y='y', fill=names(.)[i+2])) +
        scale_fill_gradient(low=col.lwr[i], high=col.upr[i],limits=c(mins[i], maxs[i])) +
        xlab('x [m]') + ylab('y [m]') + labs(cbar="test") +
        coord_fixed() + theme(text=element_text(size=9))
    }
  })
)
```

```{r, echo=FALSE, eval=FALSE}
df_merged <- merge(prior.sim, posterior.sim, by="Var2")
xlabels <- c(TeX("Prior $\\hat{\\mu}$"), TeX("Prior $\\hat{\\sigma}$"), TeX("Posterior $\\hat{\\mu}$"), TeX("Posterior $\\hat{\\sigma}$"))

xmin <- df_merged %>% select(-Var2) %>% min()
xmax <- df_merged %>% select(-Var2) %>% max()

# # png("figures/2_e.# png", width=1600, height=1200, units="px", res=300) # Saving

do.call(
  wrap_plots,
  lapply(1:4, function(i) {
    df_merged %>% {
      ggplot(.) +
      geom_histogram(aes_string(x=names(.)[i+1]), bins=40) +
      geom_vline(xintercept=mean(.[,i+1]), col="red") +
      xlim(xmin, xmax) + xlab(xlabels[i])
    }
  })
)
```


# Problem 3

Simulation:
```{r, echo=FALSE, eval=FALSE}
# Read in data
redwood <- read.table("data/redwood.dat", skip=3, col.names = c("x", "y"))
# Plot the data
#plot(redwood)

# Function to simulate Neyman-Scott process 
SimulateNSP <- function(lambda_p, lambda_d, sigma, xl = 0, xu = 1, yl = -1, yu = 0, min_d = 0) {
  # Calculate the size of the extended window
  ext_window_x <- c(xl - 2 * sigma, xu + 2 * sigma)
  ext_window_y <- c(yl - 2 * sigma, yu + 2 * sigma)
  ext_window_area <- diff(ext_window_x) * diff(ext_window_y)
  
  # Generate the parent points using a Poisson process
  n_p <- rpois(1, lambda_p * ext_window_area)
  x_p <- runif(n_p, ext_window_x[1], ext_window_x[2])
  y_p <- runif(n_p, ext_window_y[1], ext_window_y[2])
  
  # Initialize arrays to store daughter points
  x_d <- numeric()
  y_d <- numeric()
  
  # Generate daughter points around each parent point
  #browser()
  for (i in seq_along(x_p)) {
    n_d <- rpois(1, lambda_d)
    if (n_d > 0) {
      # Generate n_d daughter points around parent point i
      mu <- c(x_p[i], y_p[i])
      cov_mat <- sigma^2 * diag(2)
      # ! error on line under when n_d = 1
      d_points <- matrix(mvrnorm(n_d, mu, cov_mat), nrow = length(n_d))
      if (nrow(d_points) > 0) {  # check if d_points has more than one row
        x_d <- c(x_d, d_points[, 1])
        y_d <- c(y_d, d_points[, 2])
      }
    } else { # add min_d points if n_d is zero
      x_d <- c(x_d, rep(x_p[i], min_d))
      y_d <- c(y_d, runif(min_d, yl, yu))
    }
  }
  #browser()
  # Remove daughter points outside the specified window
  # changed the y coordinated, cannot check for -1 and 0 for y-axes here
  keep_idx <- which(x_d >= xl & x_d <= xu & y_d >= 0 & y_d <= 1)
  x_d <- x_d[keep_idx]
  y_d <- y_d[keep_idx]
  
  # Return a list of daughter points
  return(list(x = x_d, y = y_d))
}

options(error = recover)
# Set random seed for reproducibility
set.seed(4250)

# Guestimate parent intensity
lambda_p = 9

# Guestimate daughter intensity
lambda_d = 7

# Guestimate Gaussian kernel standard deviation
sigma = 0.05

# Number of realizations
nsim <- 100


# Define study area
ppregion(0, 1, 0, 1)
#ppregion(0,1,-1,0)

# Compute empirical L-function for observed
LRedwood <- Kfn(redwood, fs = 1)

# Construct a matrix to store the L-function values for each realization
Lsimulations = matrix(NA, nrow = nsim, ncol = 70)

for (i in 1:nsim) {
  sim_L <- SimulateNSP(lambda_p, lambda_d, sigma, xl = 0, xu = 1, yl = -1, yu = 0, min_d = 0)
  L_NS_temp <- Kfn(sim_L, 1, 100)
  Lsimulations[i,] <- L_NS_temp$y
}


# Utility for summary statistics dataframe:
sim_L_summary <- function(sim) {
#   Given a matrix n by m of n realizations of simulation
#   producing m values of L-fnc, calculates mean, and 90% Pi.
  L <- sim %>%
  melt(varnames=c('rel', 'r')) %>%
  mutate(r=r/max(r)) %>%
  group_by(r) %>%
  summarise(
    L_mean=mean(value),
    PI90_lwr=quantile(value, 0.05),
    PI90_upr=quantile(value, 0.95)
  )
  return(L)
}


# Summarizing statistics:
redwood.L <- sim_L_summary(Lsimulations)

```

Plot:
```{r}
# png("figures/3_1.# png", width=2400, height=2600, units="px", res=300)

# Plot redwood data and three realizations

patterns <- list(redwood)
patterns[2:4] <- replicate(3, SimulateNSP(lambda_p,lambda_d,sigma) %>% data.frame(), simplify=FALSE)

display_point_patterns(
  patterns,
  titles=c("Redwood dataset", "Redwood realization 1", "Redwood realization 2", "Redwood realization 3")
  )


# Plot
# png("figures/3_2.# png", width=2600, height=2200, units="px", res=300)
par(mfrow=c(1,1))
ggplot(redwood.L) + geom_line(aes(x=r, y=L_mean), col="red") +
  geom_ribbon(aes(x=r, ymin=PI90_lwr, ymax=PI90_upr), alpha=0.2) +
  ylab("L")
```


# Problem 4

Simulation:
```{r, echo=FALSE, eval=FALSE}
# Read in data
cells <- read.table("data/cells.dat", skip=3, col.names=c('x', 'y'))
# Plot the data
#plot(cells)

ppCells <- ppinit("cells.dat")
n_Strauss <- length(ppCells$x)

ppregion(0,1,0,1)
LCells <- Kfn(ppCells, fs=1)


#guessed parameters
r_Strauss <- 0.01
beta_Strauss <- 5
c_Strauss <- exp(-beta_Strauss)

# Number of realizations
nsim <- 100

# Construct a matrix to store the L-function values for each realization
Lsimulations_Strauss = matrix(NA, nrow = nsim, ncol = 70)

L_StraussUpper = rep(NA,70)
L_StraussLower = rep(NA,70)

ppregion()

for (i in 1:nsim) {
  sim_Strauss <- Strauss(n_Strauss,c_Strauss, r_Strauss)
  L_Strauss_temp <- Kfn(sim_Strauss, 1, 100)
  Lsimulations_Strauss[i,] <- L_Strauss_temp$y
}

# Summarizing statistics:
cells.L <- sim_L_summary(Lsimulations_Strauss)
```


Plot:
```{r}
# # png("figures/4_1.jpg", width=2400, height=2600, units="px", res=300)

#Plot of the cells data and the three simulated realizations
cells.patterns <- list(cells)
cells.patterns[2:4] <- replicate(3, Strauss(n_Strauss, c_Strauss, r_Strauss)[1:2] %>% data.frame(), simplify=FALSE)

display_point_patterns(
  cells.patterns,
  titles=c("Cells dataset", "Cells realization 1", "Cells realization 2", "Cells realization 2")
  )

# png("figures/4_2.# png", width=2600, height=2200, units="px", res=300)
par(mfrow=c(1,1))
ggplot(cells.L) + geom_line(aes(x=r, y=L_mean), col="red") +
  geom_ribbon(aes(x=r, ymin=PI90_lwr, ymax=PI90_upr), alpha=0.2) +
  ylab("L")
```

